{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0fc59fdb1acb3cbc6f619a60cab1ecbae9dda687288e1513ae2f908be914d150e",
   "display_name": "Python 3.9.2 64-bit ('gpd': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "fc59fdb1acb3cbc6f619a60cab1ecbae9dda687288e1513ae2f908be914d150e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This notebook was designed to work with [Google Colab](https://colab.research.google.com/github/lokdoesdata/syracuse-assorted/blob/main/ist_652/homework_2/lok_ngan_homework_2.ipynb).\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lokdoesdata/syracuse-assorted/blob/main/ist_652/homework_2/lok_ngan_homework_2.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# IST 652 - Homework 2: Semi-structured Data\n",
    "Lok Ngan\n",
    "\n",
    "Due: May 28, 2021\n",
    "\n",
    "-------------\n",
    "The main outline of this assignment is to show how to read in JSON data from a MongoDB collection or from a file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Set Up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Install Geopandas on Google Colab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopandas"
   ]
  },
  {
   "source": [
    "### Import libraries\n",
    "\n",
    "The library used in this script are:\n",
    "* `urlopen` from `urllib.request`, which is used to read the json files from the internet\n",
    "* `Path` from `pathlib`, which is used for I/O\n",
    "* `json`, which is used to handle json files\n",
    "* `geopandas`, which is used to read geojson files into a GeoDataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Python\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Needed Packages\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px"
   ]
  },
  {
   "source": [
    "### I/O Path"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.cwd().joinpath('data')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUTPUT_PATH = Path.cwd().joinpath('output')\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "source": [
    "## Data\n",
    "\n",
    "The data used for this assignment came from Esri.  It is the [list of ZIP Code](https://www.arcgis.com/home/item.html?id=1eeaf4bb41314febb990e2e96f7178df), summarized as points, in the United States.  This list of ZIP code includes PO Box and single site ZIP Codes, and where applicable, the population and area of each ZIP Code.\n",
    "\n",
    "In order to get to this data, the [Esri REST API](https://developers.arcgis.com/rest/) was used to query the data.  The feature server for this data set is located [here](https://services.arcgis.com/P3ePLMYs2RVChkJx/ArcGIS/rest/services/USA_ZIP_Code_Points_analysis/FeatureServer/0/).  The query output format is a JSON file.  The maximum record pull per call is 2,000 records.  A while loop was created to gather all ZIP codes data by evaluating the returned json file for the existance of property 'exceededTransferLimit'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usps_zip_code_point():\n",
    "    \"\"\"Return Esri USA ZIP Code Points as a GeoDataFrame.\n",
    "\n",
    "    Author: Lok Ngan (April 25, 2021)\n",
    "    \"\"\"\n",
    "    # Construct URL\n",
    "    URL = r'https://services.arcgis.com/P3ePLMYs2RVChkJx/ArcGIS/rest/services/'\n",
    "    URL = URL + r'USA_ZIP_Code_Points_analysis/FeatureServer/0/query?'\n",
    "    URL = URL + r'f=geojson&outFields=*&where=1=1&resultOffset='\n",
    "\n",
    "    # OUTPUT FILE goes here\n",
    "    OUTPUT_FILE = DATA_PATH.joinpath('usps_zip_code_points.geojson')\n",
    "\n",
    "    # If output file already exist, just read it!\n",
    "    if OUTPUT_FILE.is_file():\n",
    "        return(gpd.read_file(OUTPUT_FILE))\n",
    "\n",
    "    # Esri has a limit of 2,000 per pull on REST, the records can be cycled using the resultOffset parameter\n",
    "    offset = 0\n",
    "    out_features = []\n",
    "\n",
    "    # While exceeding the transfer limit, the offset will continue to go up by 2,000 until all data points are retrieved\n",
    "    while True:\n",
    "        temp_url = URL + str(offset*2000)\n",
    "\n",
    "        with urlopen(temp_url) as resp:\n",
    "            temp_json = json.load(resp)\n",
    "\n",
    "        out_features.extend(temp_json['features'])\n",
    "\n",
    "        if temp_json.get('properties') is None:\n",
    "            break\n",
    "        if temp_json.get('properties').get('exceededTransferLimit') is None:\n",
    "            break\n",
    "\n",
    "        offset += 1\n",
    "\n",
    "    # combine all of the features into a dictionary\n",
    "    out_geojson = dict(type='FeatureCollection', features=out_features)\n",
    "\n",
    "    # write dictionary into a geojson file\n",
    "    with open(OUTPUT_FILE, 'w') as out:\n",
    "        json.dump(out_geojson, out)\n",
    "\n",
    "    # Read the geojson file\n",
    "    if OUTPUT_FILE.is_file():\n",
    "        return(gpd.read_file(OUTPUT_FILE))\n",
    "\n",
    "    return(out_geojson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_usps_zip_code_point()"
   ]
  },
  {
   "source": [
    "### Dimension\n",
    "\n",
    "There are 41,080 records in the dataset across 8 columns:\n",
    "\n",
    "| Header        | Description                               |\n",
    "| :------------ | :---------------------------------------- |\n",
    "| OBJECTID      | Esri Index                                |\n",
    "| ZIP_CODE      | 5-digit USPS ZIP Code                     |\n",
    "| PO_NAME       | Post Office Name                          |\n",
    "| STATE         | State                                     |\n",
    "| ZIP_TYPE      | ZIP Code type, area or single site        |\n",
    "| POPULATION    | Population of ZIP Code                    |\n",
    "| SQMI          | Surface Area of ZIP Code in Sq Mi         |\n",
    "| geometry      | Point geometry (centroid) of the ZIP Code |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.shape"
   ]
  },
  {
   "source": [
    "### Remove Unnecessary Columns\n",
    "\n",
    "OBJECTID is the only column removed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.drop('OBJECTID', axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Evaluate for Null\n",
    "\n",
    "Population and SqMi have null values.  This makes sense as some single site ZIP codes would not have an area and would not have population.  They are filled with 0 for the purpose of this analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gdf.columns:\n",
    "    print(f\"{col} has {sum(pd.isnull(gdf[col]))} null values\")"
   ]
  },
  {
   "source": [
    "### Fill null with 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.fillna(0, inplace=True)"
   ]
  },
  {
   "source": [
    "## Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Which state has the most population?\n",
    "\n",
    "This can be done by grouping by state, and summing the population."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pop = gdf.groupby('STATE').agg({'POPULATION':'sum'})"
   ]
  },
  {
   "source": [
    "California, Texas, and Florida has the highest populations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pop.sort_values('POPULATION', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_pop = px.choropleth(\n",
    "    gdf_pop,\n",
    "    locations=gdf_pop.index, \n",
    "    locationmode='USA-states', \n",
    "    color=gdf_pop['POPULATION'], \n",
    "    scope='usa',\n",
    "    labels={'POPULATION': 'Population'}\n",
    ")\n",
    "\n",
    "fig_pop.update_layout(\n",
    "    margin=dict(r=0, t=75, l=0, b=15),\n",
    "    title_text = '2018 United States Population By States<br><sub>Data Source: Esri</sub>'\n",
    ")"
   ]
  },
  {
   "source": [
    "### Which state has the most ZIP code?\n",
    "\n",
    "This can be done by grouping by states, and counting the ZIP Codes.  Note that this step can actually be done with along with the first data question by adding another key-value to the aggregation method, but they are separated for demonstration purposes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zip_code = gdf.groupby('STATE').agg({'ZIP_CODE':'count'})"
   ]
  },
  {
   "source": [
    "Texas, California, and Pennsylvania have the most ZIP Codes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zip_code.sort_values('ZIP_CODE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_zip_code = px.choropleth(\n",
    "    gdf_zip_code,\n",
    "    locations=gdf_pop.index, \n",
    "    locationmode='USA-states', \n",
    "    color=gdf_zip_code['ZIP_CODE'], \n",
    "    scope='usa',\n",
    "    labels={'ZIP_CODE': 'ZIP Code'}\n",
    ")\n",
    "\n",
    "fig_zip_code.update_layout(\n",
    "    margin=dict(r=0, t=75, l=0, b=15),\n",
    "    title_text = 'Number of USPS ZIP Codes in Each State<br><sub>Data Source: Esri</sub>'\n",
    ")"
   ]
  },
  {
   "source": [
    "### Which ZIP code has the highest population density?\n",
    "\n",
    "Population density will be estimated using population divided by sqmi.  A list comprehension was used for the calculation. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a deepcopy of the dataframe\n",
    "gdf_density = gdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_density['pop_density'] = [pop/sqmi if sqmi > 0 else 0 for (pop, sqmi) in zip(gdf_density['POPULATION'], gdf_density['SQMI'])]"
   ]
  },
  {
   "source": [
    "Unsurprisingly, NY has the most densely populated ZIP Code in the United States.  The top 25 most densely populated ZIP Codes are all in New York."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_density.sort_values('pop_density', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pop_density = gdf_density[gdf_density['pop_density']>0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_density = px.scatter_mapbox(\n",
    "    gdf_density,\n",
    "    lat=gdf_density.geometry.y,\n",
    "    lon=gdf_density.geometry.x,\n",
    "    hover_name='ZIP_CODE',\n",
    "    hover_data=['PO_NAME', 'STATE', 'POPULATION', 'SQMI'],\n",
    "    color='pop_density',\n",
    "    size='pop_density',\n",
    "    mapbox_style='carto-positron',\n",
    "    zoom=2,\n",
    "    center={'lat': 45, 'lon': -120},\n",
    "    labels={'pop_density': 'Population<br>Density'}\n",
    ")\n",
    "\n",
    "\n",
    "fig_density.update_layout(\n",
    "    title_text = \"United States' Population Density By ZIP Code<br><sub>Data Source: Esri</sub>\",\n",
    "    margin=dict(r=0, t=75, l=0, b=15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}